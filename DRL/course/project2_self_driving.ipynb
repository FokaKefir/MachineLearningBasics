{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CarRacing-v2'\n",
    "env = gym.make(env_name, render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " {})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1.  0.  0.], 1.0, (3,), float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7654535 , 0.64423543, 0.22518677], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (96, 96, 3), uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 3\n",
    "for e in range(1, episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample() \n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        score += reward\n",
    "    print(f'Episode: {e}, score: {score}')\n",
    "#env.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\OneDrive\\Documents\\dogzilla-robot-dog-2023\\drlenv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name, render_mode='human')\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('training', 'logs')\n",
    "model = PPO(\n",
    "    'CnnPolicy',\n",
    "    env,\n",
    "    verbose=1,\n",
    "    tensorboard_log=log_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('training', 'saved models', 'project2_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training\\logs\\PPO_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 25   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 79   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008798907 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | -0.00101    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.349       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 0.73        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 369          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062112557 |\n",
      "|    clip_fraction        | 0.0687       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | 0.117        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.346        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 0.629        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 507         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007303287 |\n",
      "|    clip_fraction        | 0.0787      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | -0.00473    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.189       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 0.571       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 633        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00826563 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.11      |\n",
      "|    explained_variance   | 0.206      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.182      |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.00967   |\n",
      "|    std                  | 0.947      |\n",
      "|    value_loss           | 0.547      |\n",
      "----------------------------------------\n",
      "Logging to training\\logs\\PPO_4\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 28    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 71    |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013813084 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.0881      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.065       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 0.952       |\n",
      "|    value_loss           | 0.394       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 18        |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 330       |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0130796 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.1      |\n",
      "|    explained_variance   | 0.113     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0882    |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -0.0144   |\n",
      "|    std                  | 0.945     |\n",
      "|    value_loss           | 0.452     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 463        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01988312 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.08      |\n",
      "|    explained_variance   | 0.458      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00608    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    std                  | 0.938      |\n",
      "|    value_loss           | 0.395      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011385314 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0527      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 0.922       |\n",
      "|    value_loss           | 0.342       |\n",
      "-----------------------------------------\n",
      "Logging to training\\logs\\PPO_4\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 23    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 88    |\n",
      "|    total_timesteps | 22528 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018068694 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 0.893       |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018257875 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0594      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 0.259       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020507207 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.87       |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 0.877       |\n",
      "|    value_loss           | 0.272       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 728         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019408427 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.85       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0666      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 0.874       |\n",
      "|    value_loss           | 0.385       |\n",
      "-----------------------------------------\n",
      "Logging to training\\logs\\PPO_4\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 23    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 87    |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022675384 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    std                  | 0.848       |\n",
      "|    value_loss           | 0.301       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 401         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023871653 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0394      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    std                  | 0.84        |\n",
      "|    value_loss           | 0.301       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025489945 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0348      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    std                  | 0.83        |\n",
      "|    value_loss           | 0.346       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 717         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029241227 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0211     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    std                  | 0.823       |\n",
      "|    value_loss           | 0.246       |\n",
      "-----------------------------------------\n",
      "Logging to training\\logs\\PPO_4\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 23    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 88    |\n",
      "|    total_timesteps | 43008 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026440896 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0203      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    std                  | 0.8         |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029802166 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0262      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    std                  | 0.786       |\n",
      "|    value_loss           | 0.332       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 14         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 560        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02618765 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.5       |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.131      |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.028     |\n",
      "|    std                  | 0.775      |\n",
      "|    value_loss           | 0.418      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 716         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034090772 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00744     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    std                  | 0.762       |\n",
      "|    value_loss           | 0.393       |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "TIMESTEPS = 10_000\n",
    "for i in range(1, 6):\n",
    "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False)\n",
    "    model.save(save_path + str(i * TIMESTEPS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_path = os.path.join('training', 'saved models', 'project2_model50000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(ppo_path, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282.04864914789795, 121.89050860509542)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, score: [226.01773]\n",
      "Episode: 2, score: [309.89023]\n",
      "Episode: 3, score: [193.93756]\n"
     ]
    }
   ],
   "source": [
    "episodes = 3\n",
    "for e in range(1, episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f'Episode: {e}, score: {score}')\n",
    "#env.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training\\logs\\PPO_4\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 13    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 151   |\n",
      "|    total_timesteps | 53248 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 11         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 369        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02893966 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.38      |\n",
      "|    explained_variance   | 0.917      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0613     |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0312    |\n",
      "|    std                  | 0.748      |\n",
      "|    value_loss           | 0.577      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 10         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 584        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02848854 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.35      |\n",
      "|    explained_variance   | 0.912      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.176      |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0345    |\n",
      "|    std                  | 0.74       |\n",
      "|    value_loss           | 0.633      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 10          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 791         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031126164 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.273       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    std                  | 0.731       |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 10        |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 1005      |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0361199 |\n",
      "|    clip_fraction        | 0.287     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.29     |\n",
      "|    explained_variance   | 0.942     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0635    |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | -0.0189   |\n",
      "|    std                  | 0.73      |\n",
      "|    value_loss           | 0.408     |\n",
      "---------------------------------------\n",
      "Logging to training\\logs\\PPO_4\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 6     |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 321   |\n",
      "|    total_timesteps | 63488 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 6          |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 609        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03362003 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.24      |\n",
      "|    explained_variance   | 0.808      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.213      |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0325    |\n",
      "|    std                  | 0.718      |\n",
      "|    value_loss           | 1.02       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 845         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035540454 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.29        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    std                  | 0.712       |\n",
      "|    value_loss           | 1.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 1067        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028203722 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.2        |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.2         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    std                  | 0.707       |\n",
      "|    value_loss           | 1.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 1336        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036447164 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.329       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 0.707       |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "Logging to training\\logs\\PPO_4\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 10    |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 190   |\n",
      "|    total_timesteps | 73728 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 8           |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 464         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035280243 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0255      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    std                  | 0.693       |\n",
      "|    value_loss           | 0.796       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 8          |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 700        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03705618 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.1       |\n",
      "|    explained_variance   | 0.926      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.279      |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0205    |\n",
      "|    std                  | 0.687      |\n",
      "|    value_loss           | 0.865      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 8           |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 916         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044187635 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.06       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0711      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 0.673       |\n",
      "|    value_loss           | 0.823       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 8           |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 1166        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041773126 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.251       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.668       |\n",
      "|    value_loss           | 1.39        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "TIMESTEPS = 10_000\n",
    "for i in range(6, 9):\n",
    "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False)\n",
    "    model.save(save_path + str(i * TIMESTEPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --log_dir={log_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
