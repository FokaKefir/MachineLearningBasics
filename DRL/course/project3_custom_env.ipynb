{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gym stuff\n",
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "# Import helpers\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Import Stable baselines stuff \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type of Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discrete(3).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89639187, 0.5929647 , 0.03076255],\n",
       "       [0.11553282, 0.22215818, 0.42589325],\n",
       "       [0.23927933, 0.09014426, 0.47092372]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0, 1, shape=(3, 3)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, array([ 1,  4, -2, -1, -4], dtype=int8))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tuple((Discrete(5, start=2), Box(-5, 5, shape=(5, ), dtype=np.int8))).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('directions',\n",
       "              array([0.5876215 , 0.09161273, 0.05953738], dtype=float32)),\n",
       "             ('height', 2)])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict({'height': Discrete(3), 'directions': Box(np.array([-1, 0, 0]), 1)}).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiBinary(4).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiDiscrete([5, 2, 2, 6]).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an Environment\n",
    "- Build and agent to give us the best shower possible\n",
    "- Randomly temperaure\n",
    "- 37 and 39 degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(3)\n",
    "        self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n",
    "        self.state = np.array([38 + random.randint(-3,3)]).astype(float)\n",
    "        self.shower_length = 60\n",
    "\n",
    "    def step(self, action):\n",
    "        # Apply temp adj\n",
    "        self.state += action - 1\n",
    "\n",
    "        # Decrease shower time\n",
    "        self.shower_length -= 1\n",
    "\n",
    "        # Calculate Reward\n",
    "        if self.state >= 37 and self.state <= 39:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "\n",
    "        # Check if shower is done\n",
    "        if self.shower_length <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        info = {}\n",
    "        \n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.array([38 + random.randint(-3,3)]).astype(float)\n",
    "        self.shower_length = 60\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\OneDrive\\Documents\\dogzilla-robot-dog-2023\\drl-sb3\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "env = ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, score: -28\n",
      "Episode: 2, score: -16\n",
      "Episode: 3, score: 24\n",
      "Episode: 4, score: -52\n",
      "Episode: 5, score: -40\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for e in range(1, episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample() \n",
    "        obs, reward, done, info = env.step(action)\n",
    "\n",
    "        score += reward\n",
    "    print(f'Episode: {e}, score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training\\\\logs'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = os.path.join('training', 'logs')\n",
    "log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training\\logs\\PPO_7\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -27.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 1391     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 968         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009939802 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.000282   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -30.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 830         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012618127 |\n",
      "|    clip_fraction        | 0.0897      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.000753    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    value_loss           | 67.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -32.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 799          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104517415 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.00143     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.4         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    value_loss           | 58.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -31.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 784          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116768945 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 5.57e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    value_loss           | 67           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -31.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 759         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012642408 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.000119   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    value_loss           | 71.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -25.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 747          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047073704 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 5.35e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 41.2         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    value_loss           | 78.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -24.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004251185 |\n",
      "|    clip_fraction        | 0.00625     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.000187   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -8.71e-05   |\n",
      "|    value_loss           | 75.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -25.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011420267 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.00226     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    value_loss           | 82.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -28.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 647         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008284115 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.0014     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    value_loss           | 72.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -26         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009591589 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -1.75e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    value_loss           | 74.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -23.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009425139 |\n",
      "|    clip_fraction        | 0.0394      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.000196   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.5        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    value_loss           | 77.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -19.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 604         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008730125 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.000346   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -19.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 601          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077457232 |\n",
      "|    clip_fraction        | 0.0556       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | -0.000156    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.1         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    value_loss           | 77.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -19.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 598         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013471518 |\n",
      "|    clip_fraction        | 0.0371      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -0.00211    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    value_loss           | 78          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -22.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 594          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045762192 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.971       |\n",
      "|    explained_variance   | -1.96e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    value_loss           | 75.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -20.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 592          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039732195 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.891       |\n",
      "|    explained_variance   | 0.000243     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.6         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    value_loss           | 70.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -20.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 589          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019016624 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.852       |\n",
      "|    explained_variance   | 0.000193     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.9         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 79.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -14.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 586          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039786478 |\n",
      "|    clip_fraction        | 0.0515       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.86        |\n",
      "|    explained_variance   | 0.00217      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.7         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    value_loss           | 76.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -13         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003426379 |\n",
      "|    clip_fraction        | 0.0218      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0.00559     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.6        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.000583   |\n",
      "|    value_loss           | 81.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1f4ce498160>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training\\\\saved models\\\\project3_shower'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shower_path = os.path.join('training', 'saved models', 'project3_shower')\n",
    "shower_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(shower_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(shower_path, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-36.0, 48.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl-sb3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
