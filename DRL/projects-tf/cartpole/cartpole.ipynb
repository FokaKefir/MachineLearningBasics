{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorforce.agents import PPOAgent\n",
    "from tensorforce.execution import Runner\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v1'\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Score: 27.0\n",
      "Episode: 2, Score: 17.0\n",
      "Episode: 3, Score: 17.0\n",
      "Episode: 4, Score: 25.0\n",
      "Episode: 5, Score: 23.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes + 1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        score += reward\n",
    "    print(f\"Episode: {episode}, Score: {score}\")\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.1200185e+00, -1.3063080e+38,  1.7907065e-01, -3.3503796e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No min_value bound specified for state.\n"
     ]
    }
   ],
   "source": [
    "# https://tensorforce.readthedocs.io/en/latest/agents/ppo.html\n",
    "# https://tensorforce.readthedocs.io/en/0.2.0/agents_models.html\n",
    "agent = PPOAgent(\n",
    "    states=dict(type='float', shape=env.observation_space.shape),\n",
    "    actions=dict(type='int', num_values=env.action_space.n),\n",
    "    network=[\n",
    "        dict(type='dense', size=64),\n",
    "        dict(type='dense', size=64)\n",
    "    ],\n",
    "    batch_size=32,\n",
    "    max_episode_timesteps=500\n",
    ")\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total reward 89.0\n",
      "Episode 2: Total reward 112.0\n",
      "Episode 3: Total reward 226.0\n",
      "Episode 4: Total reward 176.0\n",
      "Episode 5: Total reward 140.0\n",
      "Episode 6: Total reward 176.0\n",
      "Episode 7: Total reward 162.0\n",
      "Episode 8: Total reward 155.0\n",
      "Episode 9: Total reward 227.0\n",
      "Episode 10: Total reward 181.0\n",
      "Episode 11: Total reward 180.0\n",
      "Episode 12: Total reward 126.0\n",
      "Episode 13: Total reward 228.0\n",
      "Episode 14: Total reward 117.0\n",
      "Episode 15: Total reward 128.0\n",
      "Episode 16: Total reward 109.0\n",
      "Episode 17: Total reward 91.0\n",
      "Episode 18: Total reward 71.0\n",
      "Episode 19: Total reward 129.0\n",
      "Episode 20: Total reward 123.0\n",
      "Episode 21: Total reward 100.0\n",
      "Episode 22: Total reward 106.0\n",
      "Episode 23: Total reward 108.0\n",
      "Episode 24: Total reward 71.0\n",
      "Episode 25: Total reward 254.0\n",
      "Episode 26: Total reward 218.0\n",
      "Episode 27: Total reward 208.0\n",
      "Episode 28: Total reward 144.0\n",
      "Episode 29: Total reward 350.0\n",
      "Episode 30: Total reward 157.0\n",
      "Episode 31: Total reward 190.0\n",
      "Episode 32: Total reward 106.0\n",
      "Episode 33: Total reward 138.0\n",
      "Episode 34: Total reward 125.0\n",
      "Episode 35: Total reward 338.0\n",
      "Episode 36: Total reward 147.0\n",
      "Episode 37: Total reward 187.0\n",
      "Episode 38: Total reward 368.0\n",
      "Episode 39: Total reward 132.0\n",
      "Episode 40: Total reward 192.0\n",
      "Episode 41: Total reward 203.0\n",
      "Episode 42: Total reward 116.0\n",
      "Episode 43: Total reward 191.0\n",
      "Episode 44: Total reward 239.0\n",
      "Episode 45: Total reward 48.0\n",
      "Episode 46: Total reward 282.0\n",
      "Episode 47: Total reward 238.0\n",
      "Episode 48: Total reward 223.0\n",
      "Episode 49: Total reward 163.0\n",
      "Episode 50: Total reward 203.0\n",
      "Episode 51: Total reward 177.0\n",
      "Episode 52: Total reward 246.0\n",
      "Episode 53: Total reward 252.0\n",
      "Episode 54: Total reward 143.0\n",
      "Episode 55: Total reward 114.0\n",
      "Episode 56: Total reward 69.0\n",
      "Episode 57: Total reward 200.0\n",
      "Episode 58: Total reward 120.0\n",
      "Episode 59: Total reward 207.0\n",
      "Episode 60: Total reward 172.0\n",
      "Episode 61: Total reward 164.0\n",
      "Episode 62: Total reward 206.0\n",
      "Episode 63: Total reward 315.0\n",
      "Episode 64: Total reward 175.0\n",
      "Episode 65: Total reward 157.0\n",
      "Episode 66: Total reward 316.0\n",
      "Episode 67: Total reward 268.0\n",
      "Episode 68: Total reward 320.0\n",
      "Episode 69: Total reward 330.0\n",
      "Episode 70: Total reward 264.0\n",
      "Episode 71: Total reward 394.0\n",
      "Episode 72: Total reward 262.0\n",
      "Episode 73: Total reward 404.0\n",
      "Episode 74: Total reward 197.0\n",
      "Episode 75: Total reward 401.0\n",
      "Episode 76: Total reward 149.0\n",
      "Episode 77: Total reward 111.0\n",
      "Episode 78: Total reward 152.0\n",
      "Episode 79: Total reward 409.0\n",
      "Episode 80: Total reward 410.0\n",
      "Episode 81: Total reward 429.0\n",
      "Episode 82: Total reward 318.0\n",
      "Episode 83: Total reward 288.0\n",
      "Episode 84: Total reward 254.0\n",
      "Episode 85: Total reward 314.0\n",
      "Episode 86: Total reward 229.0\n",
      "Episode 87: Total reward 131.0\n",
      "Episode 88: Total reward 369.0\n",
      "Episode 89: Total reward 304.0\n",
      "Episode 90: Total reward 434.0\n",
      "Episode 91: Total reward 500.0\n",
      "Episode 92: Total reward 157.0\n",
      "Episode 93: Total reward 144.0\n",
      "Episode 94: Total reward 137.0\n",
      "Episode 95: Total reward 500.0\n",
      "Episode 96: Total reward 451.0\n",
      "Episode 97: Total reward 169.0\n",
      "Episode 98: Total reward 433.0\n",
      "Episode 99: Total reward 327.0\n",
      "Episode 100: Total reward 441.0\n"
     ]
    }
   ],
   "source": [
    "train_episodes = 100\n",
    "for episode in range(1, train_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    obs = obs[0]\n",
    "    done = False \n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(obs)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        agent.observe(reward=reward, terminal=done)\n",
    "        episode_reward += reward\n",
    "        obs = next_obs\n",
    "\n",
    "    print(f'Episode {episode}: Total reward {episode_reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saved_models\\\\ppo_cartpole_2.hdf5'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.save(directory='saved_models', filename='ppo_cartpole_2', format='hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No min_value bound specified for state.\n"
     ]
    }
   ],
   "source": [
    "agent = PPOAgent.load(directory='saved_models', filename='ppo_cartpole_2', format='hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name, render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total reward 500.0\n",
      "Episode 2: Total reward 500.0\n",
      "Episode 3: Total reward 500.0\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 3\n",
    "for episode in range(1, test_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    obs = obs[0]\n",
    "    done = False \n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(obs, independent=True)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        episode_reward += reward\n",
    "        obs = next_obs\n",
    "        \n",
    "    print(f'Episode {episode}: Total reward {episode_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total reward 143.0\n",
      "Episode 2: Total reward 270.0\n",
      "Episode 3: Total reward 321.0\n",
      "Episode 4: Total reward 243.0\n",
      "Episode 5: Total reward 179.0\n",
      "Episode 6: Total reward 131.0\n",
      "Episode 7: Total reward 274.0\n",
      "Episode 8: Total reward 378.0\n",
      "Episode 9: Total reward 337.0\n",
      "Episode 10: Total reward 189.0\n",
      "Episode 11: Total reward 329.0\n",
      "Episode 12: Total reward 447.0\n",
      "Episode 13: Total reward 300.0\n",
      "Episode 14: Total reward 159.0\n",
      "Episode 15: Total reward 365.0\n",
      "Episode 16: Total reward 204.0\n",
      "Episode 17: Total reward 194.0\n",
      "Episode 18: Total reward 500.0\n",
      "Episode 19: Total reward 133.0\n",
      "Episode 20: Total reward 158.0\n",
      "Episode 21: Total reward 189.0\n",
      "Episode 22: Total reward 292.0\n",
      "Episode 23: Total reward 409.0\n",
      "Episode 24: Total reward 435.0\n",
      "Episode 25: Total reward 182.0\n",
      "Episode 26: Total reward 288.0\n",
      "Episode 27: Total reward 136.0\n",
      "Episode 28: Total reward 319.0\n",
      "Episode 29: Total reward 172.0\n",
      "Episode 30: Total reward 163.0\n",
      "Episode 31: Total reward 169.0\n",
      "Episode 32: Total reward 207.0\n",
      "Episode 33: Total reward 232.0\n",
      "Episode 34: Total reward 180.0\n",
      "Episode 35: Total reward 345.0\n",
      "Episode 36: Total reward 500.0\n",
      "Episode 37: Total reward 400.0\n",
      "Episode 38: Total reward 228.0\n",
      "Episode 39: Total reward 309.0\n",
      "Episode 40: Total reward 332.0\n",
      "Episode 41: Total reward 128.0\n",
      "Episode 42: Total reward 210.0\n",
      "Episode 43: Total reward 340.0\n",
      "Episode 44: Total reward 425.0\n",
      "Episode 45: Total reward 322.0\n",
      "Episode 46: Total reward 167.0\n",
      "Episode 47: Total reward 188.0\n",
      "Episode 48: Total reward 195.0\n",
      "Episode 49: Total reward 500.0\n",
      "Episode 50: Total reward 500.0\n",
      "Episode 51: Total reward 204.0\n",
      "Episode 52: Total reward 291.0\n",
      "Episode 53: Total reward 189.0\n",
      "Episode 54: Total reward 274.0\n",
      "Episode 55: Total reward 145.0\n",
      "Episode 56: Total reward 309.0\n",
      "Episode 57: Total reward 309.0\n",
      "Episode 58: Total reward 182.0\n",
      "Episode 59: Total reward 148.0\n",
      "Episode 60: Total reward 332.0\n",
      "Episode 61: Total reward 138.0\n",
      "Episode 62: Total reward 157.0\n",
      "Episode 63: Total reward 201.0\n",
      "Episode 64: Total reward 162.0\n",
      "Episode 65: Total reward 329.0\n",
      "Episode 66: Total reward 252.0\n",
      "Episode 67: Total reward 223.0\n",
      "Episode 68: Total reward 142.0\n",
      "Episode 69: Total reward 163.0\n",
      "Episode 70: Total reward 171.0\n",
      "Episode 71: Total reward 269.0\n",
      "Episode 72: Total reward 161.0\n",
      "Episode 73: Total reward 500.0\n",
      "Episode 74: Total reward 500.0\n",
      "Episode 75: Total reward 282.0\n",
      "Episode 76: Total reward 174.0\n",
      "Episode 77: Total reward 314.0\n",
      "Episode 78: Total reward 183.0\n",
      "Episode 79: Total reward 253.0\n",
      "Episode 80: Total reward 366.0\n",
      "Episode 81: Total reward 156.0\n",
      "Episode 82: Total reward 339.0\n",
      "Episode 83: Total reward 387.0\n",
      "Episode 84: Total reward 236.0\n",
      "Episode 85: Total reward 200.0\n",
      "Episode 86: Total reward 171.0\n",
      "Episode 87: Total reward 500.0\n",
      "Episode 88: Total reward 262.0\n",
      "Episode 89: Total reward 212.0\n",
      "Episode 90: Total reward 500.0\n",
      "Episode 91: Total reward 500.0\n",
      "Episode 92: Total reward 172.0\n",
      "Episode 93: Total reward 483.0\n",
      "Episode 94: Total reward 347.0\n",
      "Episode 95: Total reward 290.0\n",
      "Episode 96: Total reward 181.0\n",
      "Episode 97: Total reward 231.0\n",
      "Episode 98: Total reward 154.0\n",
      "Episode 99: Total reward 225.0\n",
      "Episode 100: Total reward 156.0\n"
     ]
    }
   ],
   "source": [
    "train_episodes = 100\n",
    "for episode in range(1, train_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    obs = obs[0]\n",
    "    done = False \n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(obs)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        agent.observe(reward=reward, terminal=done)\n",
    "        episode_reward += reward\n",
    "        obs = next_obs\n",
    "\n",
    "    print(f'Episode {episode}: Total reward {episode_reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorforce.agents import DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No min_value bound specified for state.\n"
     ]
    }
   ],
   "source": [
    "# https://tensorforce.readthedocs.io/en/latest/agents/dqn.html\n",
    "# https://tensorforce.readthedocs.io/en/0.2.0/agents_models.html\n",
    "agent = DQNAgent(\n",
    "    states=dict(type='float', shape=env.observation_space.shape),\n",
    "    actions=dict(type='int', num_values=env.action_space.n),\n",
    "    network=[\n",
    "        dict(type='dense', size=64),\n",
    "        dict(type='dense', size=64)\n",
    "    ],\n",
    "    batch_size=32,\n",
    "    max_episode_timesteps=500,\n",
    "    memory=1000\n",
    ")\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 1000\n",
    "for episode in range(1, train_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    obs = obs[0]\n",
    "    done = False \n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(obs)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        agent.observe(reward=reward, terminal=done)\n",
    "        episode_reward += reward\n",
    "        obs = next_obs\n",
    "\n",
    "    print(f'Episode {episode}: Total reward {episode_reward}')\n",
    "    if episode % 100 == 0:\n",
    "        agent.save(directory='saved_models', filename=f'dqn_cartpole_{episode}', format='hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No min_value bound specified for state.\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent.load(directory='saved_models', filename='dqn_cartpole_600', format='hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name, render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total reward 190.0\n",
      "Episode 2: Total reward 185.0\n",
      "Episode 3: Total reward 188.0\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 3\n",
    "for episode in range(1, test_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    obs = obs[0]\n",
    "    done = False \n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(obs, independent=True)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        episode_reward += reward\n",
    "        obs = next_obs\n",
    "        \n",
    "    print(f'Episode {episode}: Total reward {episode_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No min_value bound specified for state.\n"
     ]
    }
   ],
   "source": [
    "agent = PPOAgent(\n",
    "    states=dict(type='float', shape=env.observation_space.shape),\n",
    "    actions=dict(type='int', num_values=env.action_space.n),\n",
    "    network=[\n",
    "        dict(type='dense', size=64),\n",
    "        dict(type='dense', size=64)\n",
    "    ],\n",
    "    batch_size=32,\n",
    "    max_episode_timesteps=500,\n",
    "    summarizer=dict(\n",
    "        directory='logs/summaries',\n",
    "        summaries='all'\n",
    "    )\n",
    ")\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total reward 26.0\n",
      "Episode 2: Total reward 14.0\n",
      "Episode 3: Total reward 14.0\n",
      "Episode 4: Total reward 51.0\n",
      "Episode 5: Total reward 16.0\n",
      "Episode 6: Total reward 17.0\n",
      "Episode 7: Total reward 15.0\n",
      "Episode 8: Total reward 19.0\n",
      "Episode 9: Total reward 39.0\n",
      "Episode 10: Total reward 12.0\n",
      "Episode 11: Total reward 34.0\n",
      "Episode 12: Total reward 18.0\n",
      "Episode 13: Total reward 21.0\n",
      "Episode 14: Total reward 67.0\n",
      "Episode 15: Total reward 10.0\n",
      "Episode 16: Total reward 17.0\n",
      "Episode 17: Total reward 16.0\n",
      "Episode 18: Total reward 36.0\n",
      "Episode 19: Total reward 14.0\n",
      "Episode 20: Total reward 12.0\n",
      "Episode 21: Total reward 14.0\n",
      "Episode 22: Total reward 42.0\n",
      "Episode 23: Total reward 18.0\n",
      "Episode 24: Total reward 24.0\n",
      "Episode 25: Total reward 11.0\n",
      "Episode 26: Total reward 14.0\n",
      "Episode 27: Total reward 22.0\n",
      "Episode 28: Total reward 12.0\n",
      "Episode 29: Total reward 19.0\n",
      "Episode 30: Total reward 11.0\n",
      "Episode 31: Total reward 10.0\n",
      "Episode 32: Total reward 20.0\n",
      "Episode 33: Total reward 15.0\n",
      "Episode 34: Total reward 26.0\n",
      "Episode 35: Total reward 17.0\n",
      "Episode 36: Total reward 29.0\n",
      "Episode 37: Total reward 10.0\n",
      "Episode 38: Total reward 14.0\n",
      "Episode 39: Total reward 13.0\n",
      "Episode 40: Total reward 13.0\n",
      "Episode 41: Total reward 11.0\n",
      "Episode 42: Total reward 16.0\n",
      "Episode 43: Total reward 24.0\n",
      "Episode 44: Total reward 34.0\n",
      "Episode 45: Total reward 26.0\n",
      "Episode 46: Total reward 38.0\n",
      "Episode 47: Total reward 14.0\n",
      "Episode 48: Total reward 32.0\n",
      "Episode 49: Total reward 17.0\n",
      "Episode 50: Total reward 48.0\n",
      "Episode 51: Total reward 23.0\n",
      "Episode 52: Total reward 21.0\n",
      "Episode 53: Total reward 16.0\n",
      "Episode 54: Total reward 19.0\n",
      "Episode 55: Total reward 37.0\n",
      "Episode 56: Total reward 13.0\n",
      "Episode 57: Total reward 22.0\n",
      "Episode 58: Total reward 56.0\n",
      "Episode 59: Total reward 28.0\n",
      "Episode 60: Total reward 21.0\n",
      "Episode 61: Total reward 31.0\n",
      "Episode 62: Total reward 34.0\n",
      "Episode 63: Total reward 37.0\n",
      "Episode 64: Total reward 34.0\n",
      "Episode 65: Total reward 20.0\n",
      "Episode 66: Total reward 26.0\n",
      "Episode 67: Total reward 18.0\n",
      "Episode 68: Total reward 25.0\n",
      "Episode 69: Total reward 58.0\n",
      "Episode 70: Total reward 19.0\n",
      "Episode 71: Total reward 18.0\n",
      "Episode 72: Total reward 21.0\n",
      "Episode 73: Total reward 24.0\n",
      "Episode 74: Total reward 20.0\n",
      "Episode 75: Total reward 29.0\n",
      "Episode 76: Total reward 20.0\n",
      "Episode 77: Total reward 28.0\n",
      "Episode 78: Total reward 22.0\n",
      "Episode 79: Total reward 21.0\n",
      "Episode 80: Total reward 16.0\n",
      "Episode 81: Total reward 49.0\n",
      "Episode 82: Total reward 27.0\n",
      "Episode 83: Total reward 12.0\n",
      "Episode 84: Total reward 20.0\n",
      "Episode 85: Total reward 23.0\n",
      "Episode 86: Total reward 21.0\n",
      "Episode 87: Total reward 20.0\n",
      "Episode 88: Total reward 29.0\n",
      "Episode 89: Total reward 16.0\n",
      "Episode 90: Total reward 31.0\n",
      "Episode 91: Total reward 20.0\n",
      "Episode 92: Total reward 27.0\n",
      "Episode 93: Total reward 13.0\n",
      "Episode 94: Total reward 15.0\n",
      "Episode 95: Total reward 37.0\n",
      "Episode 96: Total reward 44.0\n",
      "Episode 97: Total reward 50.0\n",
      "Episode 98: Total reward 90.0\n",
      "Episode 99: Total reward 37.0\n",
      "Episode 100: Total reward 36.0\n",
      "Episode 101: Total reward 30.0\n",
      "Episode 102: Total reward 24.0\n",
      "Episode 103: Total reward 22.0\n",
      "Episode 104: Total reward 49.0\n",
      "Episode 105: Total reward 37.0\n",
      "Episode 106: Total reward 38.0\n",
      "Episode 107: Total reward 61.0\n",
      "Episode 108: Total reward 41.0\n",
      "Episode 109: Total reward 38.0\n",
      "Episode 110: Total reward 124.0\n",
      "Episode 111: Total reward 24.0\n",
      "Episode 112: Total reward 65.0\n",
      "Episode 113: Total reward 44.0\n",
      "Episode 114: Total reward 37.0\n",
      "Episode 115: Total reward 47.0\n",
      "Episode 116: Total reward 47.0\n",
      "Episode 117: Total reward 24.0\n",
      "Episode 118: Total reward 32.0\n",
      "Episode 119: Total reward 78.0\n",
      "Episode 120: Total reward 38.0\n",
      "Episode 121: Total reward 32.0\n",
      "Episode 122: Total reward 18.0\n",
      "Episode 123: Total reward 32.0\n",
      "Episode 124: Total reward 26.0\n",
      "Episode 125: Total reward 81.0\n",
      "Episode 126: Total reward 21.0\n",
      "Episode 127: Total reward 83.0\n",
      "Episode 128: Total reward 31.0\n",
      "Episode 129: Total reward 40.0\n",
      "Episode 130: Total reward 53.0\n",
      "Episode 131: Total reward 65.0\n",
      "Episode 132: Total reward 82.0\n",
      "Episode 133: Total reward 38.0\n",
      "Episode 134: Total reward 139.0\n",
      "Episode 135: Total reward 23.0\n",
      "Episode 136: Total reward 43.0\n",
      "Episode 137: Total reward 64.0\n",
      "Episode 138: Total reward 42.0\n",
      "Episode 139: Total reward 46.0\n",
      "Episode 140: Total reward 62.0\n",
      "Episode 141: Total reward 67.0\n",
      "Episode 142: Total reward 52.0\n",
      "Episode 143: Total reward 28.0\n",
      "Episode 144: Total reward 79.0\n",
      "Episode 145: Total reward 69.0\n",
      "Episode 146: Total reward 55.0\n",
      "Episode 147: Total reward 58.0\n",
      "Episode 148: Total reward 68.0\n",
      "Episode 149: Total reward 56.0\n",
      "Episode 150: Total reward 30.0\n",
      "Episode 151: Total reward 25.0\n",
      "Episode 152: Total reward 56.0\n",
      "Episode 153: Total reward 52.0\n",
      "Episode 154: Total reward 20.0\n",
      "Episode 155: Total reward 85.0\n",
      "Episode 156: Total reward 56.0\n",
      "Episode 157: Total reward 54.0\n",
      "Episode 158: Total reward 35.0\n",
      "Episode 159: Total reward 76.0\n",
      "Episode 160: Total reward 43.0\n",
      "Episode 161: Total reward 113.0\n",
      "Episode 162: Total reward 60.0\n",
      "Episode 163: Total reward 88.0\n",
      "Episode 164: Total reward 49.0\n",
      "Episode 165: Total reward 170.0\n",
      "Episode 166: Total reward 73.0\n",
      "Episode 167: Total reward 36.0\n",
      "Episode 168: Total reward 64.0\n",
      "Episode 169: Total reward 46.0\n",
      "Episode 170: Total reward 59.0\n",
      "Episode 171: Total reward 42.0\n",
      "Episode 172: Total reward 124.0\n",
      "Episode 173: Total reward 125.0\n",
      "Episode 174: Total reward 72.0\n",
      "Episode 175: Total reward 112.0\n",
      "Episode 176: Total reward 67.0\n",
      "Episode 177: Total reward 43.0\n",
      "Episode 178: Total reward 71.0\n",
      "Episode 179: Total reward 25.0\n",
      "Episode 180: Total reward 59.0\n",
      "Episode 181: Total reward 74.0\n",
      "Episode 182: Total reward 69.0\n",
      "Episode 183: Total reward 60.0\n",
      "Episode 184: Total reward 61.0\n",
      "Episode 185: Total reward 117.0\n",
      "Episode 186: Total reward 80.0\n",
      "Episode 187: Total reward 83.0\n",
      "Episode 188: Total reward 85.0\n",
      "Episode 189: Total reward 59.0\n",
      "Episode 190: Total reward 85.0\n",
      "Episode 191: Total reward 51.0\n",
      "Episode 192: Total reward 202.0\n",
      "Episode 193: Total reward 116.0\n",
      "Episode 194: Total reward 22.0\n",
      "Episode 195: Total reward 79.0\n",
      "Episode 196: Total reward 31.0\n",
      "Episode 197: Total reward 61.0\n",
      "Episode 198: Total reward 64.0\n",
      "Episode 199: Total reward 99.0\n",
      "Episode 200: Total reward 116.0\n",
      "Episode 201: Total reward 95.0\n",
      "Episode 202: Total reward 79.0\n",
      "Episode 203: Total reward 57.0\n",
      "Episode 204: Total reward 120.0\n",
      "Episode 205: Total reward 157.0\n",
      "Episode 206: Total reward 50.0\n",
      "Episode 207: Total reward 112.0\n",
      "Episode 208: Total reward 52.0\n",
      "Episode 209: Total reward 126.0\n",
      "Episode 210: Total reward 183.0\n",
      "Episode 211: Total reward 112.0\n",
      "Episode 212: Total reward 125.0\n",
      "Episode 213: Total reward 238.0\n",
      "Episode 214: Total reward 91.0\n",
      "Episode 215: Total reward 162.0\n",
      "Episode 216: Total reward 204.0\n",
      "Episode 217: Total reward 80.0\n",
      "Episode 218: Total reward 73.0\n",
      "Episode 219: Total reward 57.0\n",
      "Episode 220: Total reward 70.0\n",
      "Episode 221: Total reward 51.0\n",
      "Episode 222: Total reward 66.0\n",
      "Episode 223: Total reward 180.0\n",
      "Episode 224: Total reward 70.0\n",
      "Episode 225: Total reward 286.0\n",
      "Episode 226: Total reward 158.0\n",
      "Episode 227: Total reward 143.0\n",
      "Episode 228: Total reward 195.0\n",
      "Episode 229: Total reward 130.0\n",
      "Episode 230: Total reward 184.0\n",
      "Episode 231: Total reward 139.0\n",
      "Episode 232: Total reward 134.0\n",
      "Episode 233: Total reward 221.0\n",
      "Episode 234: Total reward 500.0\n",
      "Episode 235: Total reward 174.0\n",
      "Episode 236: Total reward 214.0\n",
      "Episode 237: Total reward 250.0\n",
      "Episode 238: Total reward 205.0\n",
      "Episode 239: Total reward 95.0\n",
      "Episode 240: Total reward 280.0\n",
      "Episode 241: Total reward 135.0\n",
      "Episode 242: Total reward 95.0\n",
      "Episode 243: Total reward 129.0\n",
      "Episode 244: Total reward 168.0\n",
      "Episode 245: Total reward 237.0\n",
      "Episode 246: Total reward 211.0\n",
      "Episode 247: Total reward 192.0\n",
      "Episode 248: Total reward 241.0\n",
      "Episode 249: Total reward 165.0\n",
      "Episode 250: Total reward 174.0\n",
      "Episode 251: Total reward 155.0\n",
      "Episode 252: Total reward 157.0\n",
      "Episode 253: Total reward 157.0\n",
      "Episode 254: Total reward 113.0\n",
      "Episode 255: Total reward 176.0\n",
      "Episode 256: Total reward 178.0\n",
      "Episode 257: Total reward 288.0\n",
      "Episode 258: Total reward 230.0\n",
      "Episode 259: Total reward 227.0\n",
      "Episode 260: Total reward 231.0\n",
      "Episode 261: Total reward 227.0\n",
      "Episode 262: Total reward 277.0\n",
      "Episode 263: Total reward 207.0\n",
      "Episode 264: Total reward 163.0\n",
      "Episode 265: Total reward 142.0\n",
      "Episode 266: Total reward 172.0\n",
      "Episode 267: Total reward 500.0\n",
      "Episode 268: Total reward 216.0\n",
      "Episode 269: Total reward 132.0\n",
      "Episode 270: Total reward 139.0\n",
      "Episode 271: Total reward 352.0\n",
      "Episode 272: Total reward 438.0\n",
      "Episode 273: Total reward 111.0\n",
      "Episode 274: Total reward 159.0\n",
      "Episode 275: Total reward 196.0\n",
      "Episode 276: Total reward 260.0\n",
      "Episode 277: Total reward 112.0\n",
      "Episode 278: Total reward 188.0\n",
      "Episode 279: Total reward 157.0\n",
      "Episode 280: Total reward 180.0\n",
      "Episode 281: Total reward 258.0\n",
      "Episode 282: Total reward 204.0\n",
      "Episode 283: Total reward 131.0\n",
      "Episode 284: Total reward 143.0\n",
      "Episode 285: Total reward 174.0\n",
      "Episode 286: Total reward 333.0\n",
      "Episode 287: Total reward 262.0\n",
      "Episode 288: Total reward 404.0\n",
      "Episode 289: Total reward 119.0\n",
      "Episode 290: Total reward 165.0\n",
      "Episode 291: Total reward 282.0\n",
      "Episode 292: Total reward 198.0\n",
      "Episode 293: Total reward 500.0\n",
      "Episode 294: Total reward 156.0\n",
      "Episode 295: Total reward 254.0\n",
      "Episode 296: Total reward 287.0\n",
      "Episode 297: Total reward 124.0\n",
      "Episode 298: Total reward 132.0\n",
      "Episode 299: Total reward 111.0\n",
      "Episode 300: Total reward 116.0\n",
      "Episode 301: Total reward 250.0\n",
      "Episode 302: Total reward 114.0\n",
      "Episode 303: Total reward 500.0\n",
      "Episode 304: Total reward 137.0\n",
      "Episode 305: Total reward 423.0\n",
      "Episode 306: Total reward 226.0\n",
      "Episode 307: Total reward 135.0\n",
      "Episode 308: Total reward 206.0\n",
      "Episode 309: Total reward 154.0\n",
      "Episode 310: Total reward 362.0\n",
      "Episode 311: Total reward 203.0\n",
      "Episode 312: Total reward 447.0\n",
      "Episode 313: Total reward 124.0\n",
      "Episode 314: Total reward 160.0\n",
      "Episode 315: Total reward 307.0\n",
      "Episode 316: Total reward 152.0\n",
      "Episode 317: Total reward 445.0\n",
      "Episode 318: Total reward 332.0\n",
      "Episode 319: Total reward 231.0\n",
      "Episode 320: Total reward 229.0\n",
      "Episode 321: Total reward 153.0\n",
      "Episode 322: Total reward 165.0\n",
      "Episode 323: Total reward 484.0\n",
      "Episode 324: Total reward 354.0\n",
      "Episode 325: Total reward 429.0\n",
      "Episode 326: Total reward 153.0\n",
      "Episode 327: Total reward 390.0\n",
      "Episode 328: Total reward 176.0\n",
      "Episode 329: Total reward 144.0\n",
      "Episode 330: Total reward 500.0\n",
      "Episode 331: Total reward 366.0\n",
      "Episode 332: Total reward 251.0\n",
      "Episode 333: Total reward 159.0\n",
      "Episode 334: Total reward 221.0\n",
      "Episode 335: Total reward 442.0\n",
      "Episode 336: Total reward 371.0\n",
      "Episode 337: Total reward 192.0\n",
      "Episode 338: Total reward 167.0\n",
      "Episode 339: Total reward 156.0\n",
      "Episode 340: Total reward 478.0\n",
      "Episode 341: Total reward 338.0\n",
      "Episode 342: Total reward 244.0\n",
      "Episode 343: Total reward 201.0\n",
      "Episode 344: Total reward 221.0\n",
      "Episode 345: Total reward 145.0\n",
      "Episode 346: Total reward 144.0\n",
      "Episode 347: Total reward 139.0\n",
      "Episode 348: Total reward 465.0\n",
      "Episode 349: Total reward 163.0\n",
      "Episode 350: Total reward 385.0\n",
      "Episode 351: Total reward 189.0\n",
      "Episode 352: Total reward 187.0\n",
      "Episode 353: Total reward 281.0\n",
      "Episode 354: Total reward 491.0\n",
      "Episode 355: Total reward 192.0\n",
      "Episode 356: Total reward 500.0\n",
      "Episode 357: Total reward 446.0\n",
      "Episode 358: Total reward 440.0\n",
      "Episode 359: Total reward 478.0\n",
      "Episode 360: Total reward 151.0\n",
      "Episode 361: Total reward 414.0\n",
      "Episode 362: Total reward 315.0\n",
      "Episode 363: Total reward 437.0\n",
      "Episode 364: Total reward 371.0\n",
      "Episode 365: Total reward 212.0\n",
      "Episode 366: Total reward 396.0\n",
      "Episode 367: Total reward 429.0\n",
      "Episode 368: Total reward 170.0\n",
      "Episode 369: Total reward 414.0\n",
      "Episode 370: Total reward 140.0\n",
      "Episode 371: Total reward 500.0\n",
      "Episode 372: Total reward 384.0\n",
      "Episode 373: Total reward 430.0\n",
      "Episode 374: Total reward 500.0\n",
      "Episode 375: Total reward 139.0\n",
      "Episode 376: Total reward 257.0\n",
      "Episode 377: Total reward 135.0\n",
      "Episode 378: Total reward 169.0\n",
      "Episode 379: Total reward 500.0\n",
      "Episode 380: Total reward 127.0\n",
      "Episode 381: Total reward 464.0\n",
      "Episode 382: Total reward 437.0\n",
      "Episode 383: Total reward 494.0\n",
      "Episode 384: Total reward 485.0\n",
      "Episode 385: Total reward 500.0\n",
      "Episode 386: Total reward 480.0\n",
      "Episode 387: Total reward 491.0\n",
      "Episode 388: Total reward 411.0\n",
      "Episode 389: Total reward 500.0\n",
      "Episode 390: Total reward 500.0\n",
      "Episode 391: Total reward 500.0\n",
      "Episode 392: Total reward 365.0\n",
      "Episode 393: Total reward 475.0\n",
      "Episode 394: Total reward 500.0\n",
      "Episode 395: Total reward 500.0\n",
      "Episode 396: Total reward 500.0\n",
      "Episode 397: Total reward 274.0\n",
      "Episode 398: Total reward 367.0\n",
      "Episode 399: Total reward 500.0\n",
      "Episode 400: Total reward 500.0\n",
      "Episode 401: Total reward 356.0\n",
      "Episode 402: Total reward 500.0\n",
      "Episode 403: Total reward 500.0\n",
      "Episode 404: Total reward 500.0\n",
      "Episode 405: Total reward 500.0\n",
      "Episode 406: Total reward 500.0\n",
      "Episode 407: Total reward 500.0\n",
      "Episode 408: Total reward 500.0\n",
      "Episode 409: Total reward 500.0\n",
      "Episode 410: Total reward 295.0\n",
      "Episode 411: Total reward 500.0\n",
      "Episode 412: Total reward 500.0\n",
      "Episode 413: Total reward 500.0\n",
      "Episode 414: Total reward 500.0\n",
      "Episode 415: Total reward 500.0\n",
      "Episode 416: Total reward 448.0\n",
      "Episode 417: Total reward 500.0\n",
      "Episode 418: Total reward 491.0\n",
      "Episode 419: Total reward 500.0\n",
      "Episode 420: Total reward 500.0\n",
      "Episode 421: Total reward 500.0\n",
      "Episode 422: Total reward 500.0\n",
      "Episode 423: Total reward 500.0\n",
      "Episode 424: Total reward 500.0\n",
      "Episode 425: Total reward 500.0\n",
      "Episode 426: Total reward 500.0\n",
      "Episode 427: Total reward 500.0\n",
      "Episode 428: Total reward 500.0\n",
      "Episode 429: Total reward 500.0\n",
      "Episode 430: Total reward 500.0\n",
      "Episode 431: Total reward 500.0\n",
      "Episode 432: Total reward 500.0\n",
      "Episode 433: Total reward 500.0\n",
      "Episode 434: Total reward 500.0\n",
      "Episode 435: Total reward 500.0\n",
      "Episode 436: Total reward 500.0\n",
      "Episode 437: Total reward 500.0\n",
      "Episode 438: Total reward 500.0\n",
      "Episode 439: Total reward 500.0\n",
      "Episode 440: Total reward 500.0\n",
      "Episode 441: Total reward 500.0\n",
      "Episode 442: Total reward 500.0\n",
      "Episode 443: Total reward 500.0\n",
      "Episode 444: Total reward 500.0\n",
      "Episode 445: Total reward 500.0\n",
      "Episode 446: Total reward 500.0\n",
      "Episode 447: Total reward 314.0\n",
      "Episode 448: Total reward 500.0\n",
      "Episode 449: Total reward 500.0\n",
      "Episode 450: Total reward 500.0\n",
      "Episode 451: Total reward 500.0\n",
      "Episode 452: Total reward 500.0\n",
      "Episode 453: Total reward 500.0\n",
      "Episode 454: Total reward 500.0\n",
      "Episode 455: Total reward 500.0\n",
      "Episode 456: Total reward 256.0\n",
      "Episode 457: Total reward 500.0\n",
      "Episode 458: Total reward 500.0\n",
      "Episode 459: Total reward 500.0\n",
      "Episode 460: Total reward 500.0\n",
      "Episode 461: Total reward 500.0\n",
      "Episode 462: Total reward 500.0\n",
      "Episode 463: Total reward 500.0\n",
      "Episode 464: Total reward 500.0\n",
      "Episode 465: Total reward 500.0\n",
      "Episode 466: Total reward 500.0\n",
      "Episode 467: Total reward 500.0\n",
      "Episode 468: Total reward 500.0\n",
      "Episode 469: Total reward 500.0\n",
      "Episode 470: Total reward 500.0\n",
      "Episode 471: Total reward 406.0\n",
      "Episode 472: Total reward 500.0\n",
      "Episode 473: Total reward 332.0\n",
      "Episode 474: Total reward 500.0\n",
      "Episode 475: Total reward 500.0\n",
      "Episode 476: Total reward 272.0\n",
      "Episode 477: Total reward 500.0\n",
      "Episode 478: Total reward 469.0\n",
      "Episode 479: Total reward 500.0\n",
      "Episode 480: Total reward 500.0\n",
      "Episode 481: Total reward 500.0\n",
      "Episode 482: Total reward 382.0\n",
      "Episode 483: Total reward 343.0\n",
      "Episode 484: Total reward 500.0\n",
      "Episode 485: Total reward 500.0\n",
      "Episode 486: Total reward 500.0\n",
      "Episode 487: Total reward 500.0\n",
      "Episode 488: Total reward 481.0\n",
      "Episode 489: Total reward 500.0\n",
      "Episode 490: Total reward 500.0\n",
      "Episode 491: Total reward 243.0\n",
      "Episode 492: Total reward 500.0\n",
      "Episode 493: Total reward 500.0\n",
      "Episode 494: Total reward 500.0\n",
      "Episode 495: Total reward 500.0\n",
      "Episode 496: Total reward 500.0\n",
      "Episode 497: Total reward 500.0\n",
      "Episode 498: Total reward 500.0\n",
      "Episode 499: Total reward 500.0\n",
      "Episode 500: Total reward 500.0\n"
     ]
    }
   ],
   "source": [
    "train_episodes = 500\n",
    "for episode in range(1, train_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    obs = obs[0]\n",
    "    done = False \n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(obs)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        agent.observe(reward=reward, terminal=done)\n",
    "        episode_reward += reward\n",
    "        obs = next_obs\n",
    "\n",
    "    print(f'Episode {episode}: Total reward {episode_reward}')\n",
    "    if episode % 50 == 0:\n",
    "        agent.save(directory='saved_models', filename=f'ppo_cartpole_{episode}', format='hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name, render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No min_value bound specified for state.\n"
     ]
    }
   ],
   "source": [
    "agent = PPOAgent.load(directory='saved_models', filename='ppo_cartpole_400')\n",
    "# ppo_cartpole_400, 450, 500 are acceptable models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total reward 500.0\n",
      "Episode 2: Total reward 500.0\n",
      "Episode 3: Total reward 500.0\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 3\n",
    "for episode in range(1, test_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    obs = obs[0]\n",
    "    done = False \n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(obs, independent=True)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        episode_reward += reward\n",
    "        obs = next_obs\n",
    "        \n",
    "    print(f'Episode {episode}: Total reward {episode_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
